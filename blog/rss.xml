<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="rss.xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>01010011 Blog</title>
        <link>https://bahamoth.github.io/01010011/blog</link>
        <description>01010011 Blog</description>
        <lastBuildDate>Wed, 24 Dec 2025 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ko-KR</language>
        <item>
            <title><![CDATA[일관성 있는 Agentic AI Workflow를 팀 프로젝트에 적용하는 법]]></title>
            <link>https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects</link>
            <guid>https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects</guid>
            <pubDate>Wed, 24 Dec 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[alt text]]></description>
            <content:encoded><![CDATA[<p><img decoding="async" loading="lazy" alt="alt text" src="https://bahamoth.github.io/01010011/assets/images/horse-f960ae445e5f8fb64759d5567b5da69d.png" class="img_IxQR"></p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="개요">개요<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#%EA%B0%9C%EC%9A%94" class="hash-link" aria-label="개요에 대한 직접 링크" title="개요에 대한 직접 링크">​</a></h2>
<p>코딩 에이전트가 개발의 필수 도구가 된 지금, AI를 쓰지 않는 개발자를 찾기가 오히려 어렵다. 기업들도 이 흐름에 발맞춰 OpenAI, Claude, Gemini를 종류별로 전부 구독하며 적극적인 사용을 장려한다.</p>
<p>하지만 비싼 비용을 들여 AI를 구독한다고 해서 생산성이 저절로 높아지지는 않는다.<br>
<a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/" target="_blank" rel="noopener noreferrer">METR 리서치</a>에 따르면 AI 코딩 도구를 사용했을 때 개발 완료 시간이 오히려 19% 증가했다는 결과도 있다. 개발자들은 20% 단축을 기대했지만, 실제로는 정반대였다.<br>
<!-- -->반면, SNS에서 자주 회자되는 <a href="https://www.inflearn.com/course/350%EA%B0%9C-%EA%B0%9C%EC%9D%B8%EC%95%B1-%EC%9B%94%EA%B8%897%EB%B0%B0-%EC%88%98%EC%9D%B5%EB%8B%AC%EC%84%B1%EB%B0%A9%EB%B2%95" target="_blank" rel="noopener noreferrer">프로그래밍좀비</a>라는 개발자는 AI를 활용해 350개의 앱을 개발하고 수익화에 성공했다고 한다. 중국인 개발자 <a href="https://eastondev.com/blog/en/posts/ai/20251125-ai-refactoring-10000-lines/" target="_blank" rel="noopener noreferrer">EastonDev</a>는 10,000라인 레거시 코드를 14일 만에 리팩토링하며 테스트 커버리지, 버그, 성능 지표까지 개선했다.</p>
<p>같은 도구를 쓰면서 왜 이런 생산성 차이가 생길까? 개인이 각자 알아서 AI를 사용하다 보면, 도구에 대한 이해도, 축적된 경험, 효과적인 활용법에 따라 결과가 천차만별이기 때문이다. AI 구독은 개인 능력의 상한선을 높여주지만, 그것이 곧 팀 전체의 생산성 향상으로 이어지지는 않는다.</p>
<p>이 글에서는 <strong>개인의 AI 활용 역량을 팀 전체의 역량으로 전환하는 방법</strong>을 다룬다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="llm과-harness의-한계">LLM과 Harness의 한계<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#llm%EA%B3%BC-harness%EC%9D%98-%ED%95%9C%EA%B3%84" class="hash-link" aria-label="LLM과 Harness의 한계에 대한 직접 링크" title="LLM과 Harness의 한계에 대한 직접 링크">​</a></h2>
<p>LLM의 한계는 이미 잘 알려진 내용이므로 깊이 다루지는 않겠다. 다만 트랜스포머 기반 AI에게 업무를 맡길 때 반드시 인지해야 할 본질적 한계를 짚고 넘어가보자.</p>
<p><strong>1. 컨텍스트는 유한하다</strong></p>
<p>아무리 컨텍스트 윈도우가 커져도, 긴 맥락이 필요한 작업에는 여전히 한계가 있다. 대규모 코드베이스 전체를 이해하거나, 수십 개 파일에 걸친 리팩토링을 한 번에 처리하기는 어렵다. 이를 해결하려면 <a href="https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents" target="_blank" rel="noopener noreferrer">맥락을 효과적으로 전달하는 별도의 방법</a>을 고안해야 한다.</p>
<p><strong>2. 결과물은 확률적이다</strong></p>
<p>같은 프롬프트에도 매번 다른 결과가 나온다. 이는 LLM의 <a href="https://huggingface.co/blog/how-to-generate" target="_blank" rel="noopener noreferrer">근본적인 생성 방식</a> 때문이다. 창의적인 작업에서는 장점이 되지만, 일관성이 필요한 작업에서는 치명적인 단점이 된다.</p>
<p><strong>3. 환각은 피할 수 없다</strong></p>
<p>LLM은 자신 있는 어조로 틀린 정보를 생성한다. 코딩 맥락에서는 존재하지 않는 API를 호출하거나, deprecated된 문법을 최신인 것처럼 제안하거나, 아예 없는 라이브러리를 import하는 코드를 만들어낸다. 문제는 이런 환각이 그럴듯해 보인다는 것이다. 검증 없이 AI의 출력을 그대로 믿으면, 컴파일 에러는 그나마 다행이고 런타임에서나 확인하는 대형사고로 이어질 수 있다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="harness-현실적인-해결책">Harness: 현실적인 해결책<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#harness-%ED%98%84%EC%8B%A4%EC%A0%81%EC%9D%B8-%ED%95%B4%EA%B2%B0%EC%B1%85" class="hash-link" aria-label="Harness: 현실적인 해결책에 대한 직접 링크" title="Harness: 현실적인 해결책에 대한 직접 링크">​</a></h3>
<p>이러한 한계를 보완하는 여러 방법 중, 현재 가장 제품 수준의 완성도를 보여주는 것이 <strong>Harness</strong>(Tool Use 기반의 에이전트 구조)다. Claude Code, Cursor, Windsurf 같은 코딩 에이전트들이 이 방식을 채택하고 있다.</p>
<p>하지만 Harness에는 <code>**유효기간**</code>이 있다.</p>
<p><a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" target="_blank" rel="noopener noreferrer">Bitter Lesson</a>의 깨달음, Scaling Law는 여전히 유효하다. 어느 날 갑자기 Google이나 OpenAI의 신모델이 등장해, 팀이 공들여 구축한 Harness를 무용지물로 만들 수 있다. 실제로 예전에는 PDF에서 텍스트를 추출하려면 복잡한 파이프라인이 필요했지만, 이제는 멀티모달 모델에 이미지로 던지면 끝이다. 팀이 몇 주간 구축한 PDF 파싱 Harness가 하룻밤 사이에 레거시가 되어버리는 것이다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="그럼에도-harness를-만들어야-하는-이유">그럼에도 Harness를 만들어야 하는 이유<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#%EA%B7%B8%EB%9F%BC%EC%97%90%EB%8F%84-harness%EB%A5%BC-%EB%A7%8C%EB%93%A4%EC%96%B4%EC%95%BC-%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0" class="hash-link" aria-label="그럼에도 Harness를 만들어야 하는 이유에 대한 직접 링크" title="그럼에도 Harness를 만들어야 하는 이유에 대한 직접 링크">​</a></h3>
<p>이런 리스크에도 불구하고, <a href="https://www.businessinsider.com/ai-coding-agents-adoption-top-tools-2025-8" target="_blank" rel="noopener noreferrer">지금 당장 Harness가 제공하는 생산성 향상</a>은 무시할 수 없다.</p>
<p>Harness 없이 Raw LLM만 쓰는 것과, 잘 구성된 에이전트 환경에서 작업하는 것의 생산성 격차는 이미 크게 벌어졌다. 6개월 뒤 무용지물이 될 수 있다 해도, 그 6개월간의 생산성 이득이 구축 비용을 상회한다면 만들어야 한다.</p>
<p>문제는 <strong>이 Harness를 개인이 아닌 팀 전체가 일관되게 사용하도록 만드는 것</strong>이다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="개인의-ai-역량--팀의-ai-역량">개인의 AI 역량 ≠ 팀의 AI 역량<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#%EA%B0%9C%EC%9D%B8%EC%9D%98-ai-%EC%97%AD%EB%9F%89--%ED%8C%80%EC%9D%98-ai-%EC%97%AD%EB%9F%89" class="hash-link" aria-label="개인의 AI 역량 ≠ 팀의 AI 역량에 대한 직접 링크" title="개인의 AI 역량 ≠ 팀의 AI 역량에 대한 직접 링크">​</a></h2>
<p>AI를 잘 쓰는 개인은 많다. 하지만 그 개인이 속한 팀이 AI를 잘 쓰는가는 전혀 다른 문제다.</p>
<p>팀원들에게 비싼 AI 구독을 제공한다고 해서 팀 생산성이 저절로 높아지지 않는다. 개인 단위의 AI 활용이 팀 단위의 생산성으로 전환되지 못하는 데는 구조적인 이유가 있다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="1-인간-지능이-병목이다">1. 인간 지능이 병목이다<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#1-%EC%9D%B8%EA%B0%84-%EC%A7%80%EB%8A%A5%EC%9D%B4-%EB%B3%91%EB%AA%A9%EC%9D%B4%EB%8B%A4" class="hash-link" aria-label="1. 인간 지능이 병목이다에 대한 직접 링크" title="1. 인간 지능이 병목이다에 대한 직접 링크">​</a></h3>
<p>AI의 코드 생산 속도는 인간의 리뷰 속도를 아득히 넘어선다. <a href="https://www.itworld.co.kr/article/4062051" target="_blank" rel="noopener noreferrer">ITWorld의 분석</a>에 따르면, 이는 "조립 라인에서 한 기계만 속도를 높이고 나머지를 그대로 두면, 공장이 빨라지는 것이 아니라 처리되지 못한 작업이 쌓여갈 뿐"인 상황과 같다. 코드는 10배 빨리 생성되는데, 리뷰는 여전히 사람이 일일이 해야 한다면 결국 인간 리뷰어가 병목이 될 수 밖에 없다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="2-검증-체계가-없다">2. 검증 체계가 없다<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#2-%EA%B2%80%EC%A6%9D-%EC%B2%B4%EA%B3%84%EA%B0%80-%EC%97%86%EB%8B%A4" class="hash-link" aria-label="2. 검증 체계가 없다에 대한 직접 링크" title="2. 검증 체�계가 없다에 대한 직접 링크">​</a></h3>
<p>AI가 생성한 코드를 얼마나 신뢰할 수 있는가? <a href="https://www.itworld.co.kr/article/4110154" target="_blank" rel="noopener noreferrer">코드래빗 보고서</a>에 따르면, AI 생성 코드는 사람이 작성한 코드보다 PR당 1.7배 더 많은 이슈를 발생시킨다. 객관적인 검증 지표와 자동화된 품질 게이트 없이는, AI 결과물에 대한 확신을 가질 수 없다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="3-숙련도-격차가-크다">3. 숙련도 격차가 크다<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#3-%EC%88%99%EB%A0%A8%EB%8F%84-%EA%B2%A9%EC%B0%A8%EA%B0%80-%ED%81%AC%EB%8B%A4" class="hash-link" aria-label="3. 숙련도 격차가 크다에 대한 직접 링크" title="3. 숙련도 격차가 크다에 대한 직접 링크">​</a></h3>
<p>누군가는 정교한 프롬프트와 최적화된 에이전트 설정으로 높은 품질의 결과물을 뽑아내지만, 누군가는 기본적인 활용에도 어려움을 겪는다. 같은 도구, 같은 구독료를 내면서도 생산성 격차는 몇 배씩 벌어진다. 이 격차를 좁히는 것은 개인의 노력만으로는 한계가 있다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="4-경험과-노하우가-휘발된다">4. 경험과 노하우가 휘발된다<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#4-%EA%B2%BD%ED%97%98%EA%B3%BC-%EB%85%B8%ED%95%98%EC%9A%B0%EA%B0%80-%ED%9C%98%EB%B0%9C%EB%90%9C%EB%8B%A4" class="hash-link" aria-label="4. 경험과 노하우가 휘발된다에 대한 직접 링크" title="4. 경험과 노하우가 휘발된다에 대한 직접 링크">​</a></h3>
<p>가장 심각한 문제다. 비슷한 업무를 하는 팀원들이 각자 비슷한 프롬프트를 만들고, 비슷한 에이전트 구성을 시도한다. 누군가 효과적인 방법을 발견해도, 그 지식은 개인에게 머문다. 슬랙에 공유한 팁은 며칠 뒤 묻히고, 노션에 정리한 가이드는 업데이트되지 않는다. <strong>AI를 잘 쓰는 경험과 노하우가 팀에 축적되지 않고 휘발된다.</strong></p>
<hr>
<p>이 네 가지 문제의 공통점은 무엇인가? <strong>AI 역량을 축적하고 공유할 워크플로우의 부재</strong>다.</p>
<p>개인의 역량에 의존하는 한, 팀 전체의 AI 활용 수준은 들쭉날쭉할 수밖에 없다. 필요한 것은 개인의 경험이 팀의 자산으로 축적되고, 검증된 워크플로우가 모든 팀원에게 일관되게 적용되는 구조다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="ai-시대-리더가-해야-할-일">AI 시대, 리더가 해야 할 일<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#ai-%EC%8B%9C%EB%8C%80-%EB%A6%AC%EB%8D%94%EA%B0%80-%ED%95%B4%EC%95%BC-%ED%95%A0-%EC%9D%BC" class="hash-link" aria-label="AI 시대, 리더가 해야 할 일에 대한 직접 링크" title="AI 시대, 리더가 해야 할 일에 대한 직접 링크">​</a></h2>
<p>앞으로 모든 기술 리더는 <strong>개인의 경험이 팀의 자산으로 축적되는 구조</strong>를 설계해야 한다. 이것은 비단 AI Era만 해당되는 이야기가 아니다. 다만 AI 시대에는 앞서 언급한 이 문제가 첨예해졌을 뿐이다.</p>
<p>리더의 역할은 적극적으로 Harness를 구축하고, 이를 팀 워크플로우에 녹여내는 것이다. 다음은 이를 위한 다섯 가지 원칙이다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="1-워크플로우-단계별로-맥락을-분리하라">1. 워크플로우 단계별로 맥락을 분리하라<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#1-%EC%9B%8C%ED%81%AC%ED%94%8C%EB%A1%9C%EC%9A%B0-%EB%8B%A8%EA%B3%84%EB%B3%84%EB%A1%9C-%EB%A7%A5%EB%9D%BD%EC%9D%84-%EB%B6%84%EB%A6%AC%ED%95%98%EB%9D%BC" class="hash-link" aria-label="1. 워크플로우 단계별로 맥락을 분리하라에 대한 직접 링크" title="1. 워크플로우 단계별로 맥락을 분리하라에 대한 직접 링크">​</a></h3>
<p>하나의 거대한 프롬프트로 모든 것을 해결하려 하지 마라. 기획 검토, 설계, 구현, 테스트, 리뷰 - 각 단계는 필요로 하는 맥락이 다르다. 단계마다 적절한 컨텍스트만 전달하면 LLM의 유한한 컨텍스트 윈도우를 효율적으로 활용할 수 있고, 결과물의 품질도 높아진다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="2-결정적-작업deterministic-tasks과-비결정적-작업non-deterministic-task을-구분하라">2. 결정적 작업(Deterministic Tasks)과 비결정적 작업(Non-Deterministic Task)을 구분하라<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#2-%EA%B2%B0%EC%A0%95%EC%A0%81-%EC%9E%91%EC%97%85deterministic-tasks%EA%B3%BC-%EB%B9%84%EA%B2%B0%EC%A0%95%EC%A0%81-%EC%9E%91%EC%97%85non-deterministic-task%EC%9D%84-%EA%B5%AC%EB%B6%84%ED%95%98%EB%9D%BC" class="hash-link" aria-label="2. 결정적 작업(Deterministic Tasks)과 비결정적 작업(Non-Deterministic Task)을 구분하라에 대한 직접 링크" title="2. 결정적 작업(Deterministic Tasks)과 비결정적 작업(Non-Deterministic Task)을 구분하라에 대한 직접 링크">​</a></h3>
<p>모든 것에 LLM을 쓸 필요는 없다.</p>
<p><strong>결정적 작업</strong>은 규칙 기반으로 항상 같은 결과를 내야 하는 작업이다. 린팅, 포매팅, 정적 분석, 타입 체크, 보안 스캔이 여기에 해당한다. 이런 작업에 LLM을 쓰면 불필요한 비용과 불확실성만 늘어난다. 전통적인 도구가 더 빠르고, 더 정확하고, 더 일관적이다.</p>
<p><strong>비결정적 작업</strong>은 맥락 이해와 판단이 필요한 작업이다. 여기가 LLM이 진가를 발휘하는 영역이다:</p>
<ul>
<li><strong>Tidying</strong>: 변수명 개선, 불필요한 중복 제거 같은 작은 정리 작업</li>
<li><strong>Reviewing</strong>: 잠재적 버그 탐지, 성능 이슈 지적, 컨벤션 위반 발견</li>
<li><strong>문서화</strong>: 코드 주석, README, API 문서, CHANGELOG 작성</li>
<li><strong>테스트 생성</strong>: 단위 테스트 작성, 엣지 케이스 도출, 테스트 커버리지 확장</li>
</ul>
<p>결정적 작업은 CI 파이프라인에 맡기고, LLM은 비결정적 작업에 집중시켜라.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="3-변경-범위를-작게-유지하라">3. 변경 범위를 작게 유지하라<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#3-%EB%B3%80%EA%B2%BD-%EB%B2%94%EC%9C%84%EB%A5%BC-%EC%9E%91%EA%B2%8C-%EC%9C%A0%EC%A7%80%ED%95%98%EB%9D%BC" class="hash-link" aria-label="3. 변경 범위를 작게 유지하라에 대한 직접 링크" title="3. 변경 범위를 작게 유지하라에 대한 직접 링크">​</a></h3>
<p>AI가 한 번에 수천 줄을 생성할 수 있다고 해서, 매번 수천 줄을 생성해야 하는 것은 아니다. 큰 변경은 리뷰어의 인지 부하를 높이고 병목을 유발한다. 충분히 검증 가능하고, 문제가 생겨도 쉽게 롤백할 수 있는 작은 단위로 변경을 쪼개야 한다.</p>
<p>그렇다고 무조건 작게만 유지하라는 것은 아니다. 핵심은 <strong>인지 부하 없이 자동 검증 가능한 범위</strong>를 찾는 것이다.</p>
<p>Kent Beck은 <a href="https://www.oreilly.com/library/view/tidy-first/9781098151232/" target="_blank" rel="noopener noreferrer">Tidy First?</a>에서 리팩토링보다 작고 린팅보다는 의미 있는 'Tidying'이라는 개념을 제안한다. 예를 들어:</p>
<ul>
<li>가드 클로즈로 중첩 조건문 펼치기</li>
<li>설명하는 변수명으로 매직 넘버 대체하기</li>
<li>죽은 코드 제거하기</li>
<li>함수 순서 재배치하기</li>
</ul>
<p>이 정도 규모의 변경은 테스트만 통과하면 별도 리뷰 없이 머지해도 된다. 워크플로우를 잘 설계하면 이런 Tidying 작업을 AI가 자동으로 수행하고, 자동으로 검증하고, 자동으로 적용하는 것이 가능하다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="4-인간-개입을-최소화할-수-있는-워크플로우를-만들어라">4. 인간 개입을 최소화할 수 있는 워크플로우를 만들어라<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#4-%EC%9D%B8%EA%B0%84-%EA%B0%9C%EC%9E%85%EC%9D%84-%EC%B5%9C%EC%86%8C%ED%99%94%ED%95%A0-%EC%88%98-%EC%9E%88%EB%8A%94-%EC%9B%8C%ED%81%AC%ED%94%8C%EB%A1%9C%EC%9A%B0%EB%A5%BC-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%9D%BC" class="hash-link" aria-label="4. 인간 개입을 최소화할 수 있는 워크플로우를 만들어라에 대한 직접 링크" title="4. 인간 개입을 최소화할 수 있는 워크플로우를 만들어라에 대한 직접 링크">​</a></h3>
<p>병목은 결국 인간이다. AI의 생산 속도를 인간의 리뷰 속도가 따라갈 수 없다면, 인간 개입을 최소화하여 AI 결과물을 검증할 수 있는 자동화된 워크플로우가 필요하다.</p>
<p>일반적으로 검증 워크플로우는 계층적으로 구성된다:</p>
<p><strong>1차: 결정적 검증 (CI 파이프라인)</strong></p>
<ul>
<li>린팅, 포매팅, 타입 체크 통과 여부</li>
<li>테스트 스위트 전체 통과 여부</li>
<li>보안 스캔, 의존성 취약점 검사</li>
</ul>
<p><strong>2차: 비결정적 검증 (AI 리뷰어)</strong></p>
<ul>
<li>PR이 생성되면 리뷰어 에이전트가 변경점을 분석</li>
<li>잠재적 버그, 성능 이슈, 아키텍처 위반 탐지</li>
<li>PR 변경의 핵심 포인트 요약 및 개선 제안</li>
</ul>
<p><strong>3차: 범위 기반 자동 승인</strong></p>
<ul>
<li>Tidying 수준의 작은 변경 + 1차/2차 검증 통과 → 자동 머지</li>
<li>버저닝을 유발하는 큰 변경 → 리뷰 생성</li>
</ul>
<p>여기서 <a href="https://www.conventionalcommits.org/" target="_blank" rel="noopener noreferrer">Conventional Commits</a> 규칙이 에이전트에게 힌트를 줄 수 있다. 커밋 메시지에 <code>feat:</code>, <code>fix:</code>, <code>refactor:</code>, <code>chore:</code>, <code>docs:</code> 같은 타입과 <code>!</code>(breaking change) 표시를 강제하면, AI가 변경의 성격과 영향 범위를 명확히 판단할 수 있다.</p>
<div class="codeBlockContainer_CCLs theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_SaVD"><pre tabindex="0" class="prism-code language-text codeBlock_Z7Ay thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_LibW"><span class="token-line" style="color:#393A34"><span class="token plain">chore: 미사용 import 제거          → 자동 머지 가능</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">refactor: 결제 로직 함수 분리      → AI 리뷰 후 자동 머지</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">feat!: 인증 API 응답 구조 변경     → 별도의 리뷰 프로세스 필요</span><br></span></code></pre><div class="buttonGroup_ILbZ"><button type="button" aria-label="클립보드에 코드 복사" title="복사" class="clean-btn"><span class="copyButtonIcons_Dv9x" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_Hdzs"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_Zyxa"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>이렇게 구성하면 버저닝을 유발하는 큰 변경이 아닌 <code>chore</code>, <code>style</code>, <code>docs</code>, <code>refactor</code> 수준의 변경은 1차/2차 검증만 통과하면 리뷰어 에이전트가 직접 머지할 수 있다. <code>feat!</code>, <code>fix!</code> 같은 breaking change나 <code>feat</code> 같은 의미 있는 변경만 별도의 리뷰 프로세스를 도입하면 된다.</p>
<p>이 워크플로우의 수준이 높아져서 다소 큰 변경마저도 리뷰 에이전트가 인간 지능 개입 없이 머지가능한 수준으로 고도화된다면 결국 대부분의 변경이 인간 개입 없이 자동으로 처리되고, 이 팀/프로젝트의 생산성은 큰 변곡점을 맞게 될 것이다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="5-모든-개선이-팀의-자산으로-축적되게-하라">5. 모든 개선이 팀의 자산으로 축적되게 하라<a href="https://bahamoth.github.io/01010011/blog/how-to-build-a-consistent-agentic-ai-workflow-for-team-projects#5-%EB%AA%A8%EB%93%A0-%EA%B0%9C%EC%84%A0%EC%9D%B4-%ED%8C%80%EC%9D%98-%EC%9E%90%EC%82%B0%EC%9C%BC%EB%A1%9C-%EC%B6%95%EC%A0%81%EB%90%98%EA%B2%8C-%ED%95%98%EB%9D%BC" class="hash-link" aria-label="5. 모든 개선이 팀의 자산으로 축적되게 하라에 대한 직접 링크" title="5. 모든 개선이 팀의 자산으로 축적되게 하라에 대한 직접 링크">​</a></h3>
<p><strong>이것이 가장 중요하다.</strong></p>
<p>AI 도입은 "좋은 도구를 사주면 끝나는" 문제가 아니다. <a href="https://dora.dev/research/2025/dora-report/" target="_blank" rel="noopener noreferrer">2025 DORA 리포트</a>는 성공적인 AI 도입을 툴 문제가 아니라 시스템 문제로 정의하며, AI의 가치는 도구 그 자체보다 주변의 기술·문화적 환경에 Lock-in 된다고 말한다.</p>
<p>누군가 효과적인 프롬프트를 발견했다면, 그 프롬프트는 휘발되지 않고 팀 전체가 쓰는 도구에 반영되어야 한다. 누군가 실수를 방지하는 워크플로우를 만들었다면, 그 워크플로우는 개인의 습관이 아니라 팀의 시스템으로 자리 잡아야 한다.</p>
<p>개인이 발견한 베스트 프랙티스가 → 팀의 표준 워크플로우가 되고 → 버전 관리되며 → 지속적으로 개선되는 구조.</p>
<p>이 구조가 작동하려면, 조직은 <strong>명확하고 공유된 AI 스탠스(정책/기대치/허용 도구/적용 범위)</strong> 를 가져야 한다. DORA 리포트는 AI 도입의 긍정적 효과가 이런 "clear and communicated AI stance"의 존재에 의존하며, 이것이 있을 때 개인 효과와 조직 성과의 긍정적 영향이 증폭된다고 제시한다.</p>
<p>이것을 가능하게 하는 것이 AI 시대 리더십의 핵심 역할이다.</p>
<hr>
<p>다음 편에서는 이 원칙들을 Claude Code의 Skills, Hooks, Plugins로 구현하는 구체적인 방법을 살펴보겠다.</p>]]></content:encoded>
            <category>agenticai</category>
            <category>ai</category>
            <category>claudecode</category>
            <category>agentskill</category>
            <category>harness</category>
        </item>
        <item>
            <title><![CDATA[Mobile Attribution in the Privacy First Era]]></title>
            <link>https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era</link>
            <guid>https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era</guid>
            <pubDate>Tue, 16 Sep 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[alt text]]></description>
            <content:encoded><![CDATA[<p><img decoding="async" loading="lazy" alt="alt text" src="https://bahamoth.github.io/01010011/assets/images/broken_bridge-a9da819679aaa5ace7d489bafe8bbb07.png" class="img_IxQR"></p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="개요">개요<a href="https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era#%EA%B0%9C%EC%9A%94" class="hash-link" aria-label="개요에 대한 직접 링크" title="개요에 대한 직접 링크">​</a></h2>
<p>개인정보 보호의 중요성이 대두되면서 모바일 어트리뷰선의 패러다임은 크게 변화하였다. 과거에는 IDFA, GAID 등의 광고 식별자를 통해 명확한 측정이 가능하였으나, 사용자의 개인정보 보호를 최우선으로 하는 현대에는 더이상 Deterministic한 사용자 식별이 불가능하다.</p>
<p>이 글에서는 Apple의 SKAdNetwork(SKAN)와 Google의 Privacy Sandbox로 대표하는 모바일 환경의 개인정보 보호 프레임워크에 대해 설명하고, 어떻게 확률론적으로 모바일 어트리뷰선을 획득하는지에 대해 알아보겠다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="어떻게-알고-오셨어요">어떻게 알고 오셨어요?<a href="https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era#%EC%96%B4%EB%96%BB%EA%B2%8C-%EC%95%8C%EA%B3%A0-%EC%98%A4%EC%85%A8%EC%96%B4%EC%9A%94" class="hash-link" aria-label="어떻게 알고 오셨어요?에 대한 직접 링크" title="어떻게 알고 오셨어요?에 대한 직접 링크">​</a></h3>
<p>1970년대, 미국 디트로이트의 자동차 판매원 '조 지라드(Joe Girard)'는 15년간 13,001대의 차를 팔아 '세계에서 가장 위대한 세일즈맨'으로 기네스북에 올랐다.</p>
<p>그의 성공 비결은 차를 파는 기술이 아니라, 고객을 끊임없이 만들어내는 '시스템'에 있었다. 그는 자신의 고객이 될 만한 사람을 소개해 주는 사람들을 <strong>'버드 도그(Bird Dogs, 사냥개)'</strong> 라고 불렀다. 이발사, 식당 주인, 은행원 등 주변의 모든 사람이 그의 '버드 도그'가 될 수 있었다.<br>
<!-- -->그의 규칙은 간단했다. "저에게 손님을 보내주십시오. 그 손님이 차를 사면, 제가 바로 당신에게 25달러를 보내드리겠습니다."<br>
<!-- -->이 시스템이 완벽하게 돌아가려면 가장 중요한 전제 조건이 있었다. 바로 <strong>"이 고객을 누가 보냈는가?"</strong> 를 한 치의 오차도 없이 파악하는 것이었다.<br>
<!-- -->조 지라드는 새로운 고객이 오면 가장 먼저 "누가 당신을 제게 보냈습니까?"라고 물었다. 그리고 판매가 성사되면 장부에 꼼꼼히 기록해 두었다가, 약속한 25달러를 소개자에게 반드시 보냈다.</p>
<p>조 지라드의 일화와 마찬가지로 모바일 앱 서비스 생태계에서는 어떤 광고활동이나 마케팅이 고객의 유입이나 결제로 이어졌는지 추적하고 그 공로를 찾아내는데, 그 과정을 Mobile Attribution 이라고 한다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="deterministic-attribution">Deterministic Attribution<a href="https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era#deterministic-attribution" class="hash-link" aria-label="Deterministic Attribution에 대한 직접 링크" title="Deterministic Attribution에 대한 직접 링크">​</a></h2>
<p>Attribution을 정확히 측정하는 것은 매우 중요하다. 이 손님이 이발사의 소개를 받고 왔는지, 은행원의 소개를 받고 왔는지를 알아야 누구에게 얼마의 광고료를 줄지 판단할 수 있기 때문이다.<br>
<!-- -->'이 손님은 누구의 소개를 받고 왔는가?' 이 질문에 답하기 위해 모바일 플랫폼은 Ad Network에게 다음 정보를 전달하였다.</p>
<ul>
<li><strong>IDFA (Identifier for Advertisers):</strong> Apple이 iOS 기기를 위해 제공하는, 사용자가 재설정할 수 있는 광고 식별자</li>
<li><strong>GAID (Google Advertising ID):</strong> Google이 Google Play 서비스가 설치된 Android 기기를 위해 제공하는 광고 식별자</li>
</ul>
<p>IDFA, GAID는 모두 사용자의 기기를 정확히 식별할 수 있는 고유의 값이다. 따라서 IDFA 와 GAID 를 알면 정확한 Mobile Attribution을 획득할 수 있다.</p>
<ol>
<li>사용자가 광고를 클릭</li>
<li>Ad Network는 해당 기기의 IDFA / GAID를 캡처 후 저장</li>
<li>사용자가 앱을 설치, 처음으로 실행</li>
<li>100% 정확한 사용자 유입 경로를 알 수 있는 Attribution 획득</li>
</ol>
<p>이러한 Deterministic 한 Attribution 획득 방식으로 인해, 광고주들은 어떤 광고가 어떤 사용자를 유입시켰는지에 대한 명확한 데이터를 확보할 수 있었고, 이는 모바일 광고 생태계를 성장시키는 기반이었다. 하지만 이제 공짜점심은 끝났다. 모바일 플랫폼의 개인정보 보호 강화 기조 아래, 사용자 동의 없이 Deterministic Attribution 획득은 불가능하다. 이 글을 읽고 있는 당신도 그러겠지만, 사용자들은 더 이상 나를 특정할 수 있는 개인정보 제공에 동의하지 않는다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="probabilistic-attribution">Probabilistic Attribution<a href="https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era#probabilistic-attribution" class="hash-link" aria-label="Probabilistic Attribution에 대한 직접 링크" title="Probabilistic Attribution에 대한 직접 링크">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="apple의-attapptrackingtransparency와-skanskadnetwork-framework">Apple의 ATT(AppTrackingTransparency)와 SKAN(SKAdNetwork) Framework<a href="https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era#apple%EC%9D%98-attapptrackingtransparency%EC%99%80-skanskadnetwork-framework" class="hash-link" aria-label="Apple의 ATT(AppTrackingTransparency)와 SKAN(SKAdNetwork) Framework에 대한 직접 링크" title="Apple의 ATT(AppTrackingTransparency)와 SKAN(SKAdNetwork) Framework에 대한 직접 링크">​</a></h3>
<p>상술하였듯, 애플은 더 이상 사용자 동의 없이 IDFA를 제공하지 않는다.(정확히 말하면 '명시적인' 사용자 동의 없이).</p>
<p><img decoding="async" loading="lazy" alt="empty IDFA" src="https://bahamoth.github.io/01010011/assets/images/empty_idfa-bf26f67053730531a55d9b54cf23289b.png" class="img_IxQR"></p>
<p>따라서 iOS14+ 이후부터는 기기의 IDFA 값을 가져오려면 ATT(AppTrackingTransparency) 프레임워크를 통해 반드시 명시적으로 사용자의 권한을 획득하여야 한다. 사용자가 동의를 거부하면 상기 스샷과 같이 IDFA 값은 000000~ 으로 비워진다.</p>
<p>이는 광고주 및 Ad Network 모두에게 치명적인 문제다. 내 광고가 누구에 의해 노출이 되었는지 명확히 알지 못하기 때문에 어느 경로를 통해 고객이 유입되었는지 파악할 수 없고, 광고 비즈니스의 대전제(어떻게 알고 오셨어요?)가 무너지게 된다.</p>
<p>대안으로, 애플은 개인을 특정할 수는 없는 제한된 정보를 제공하는 광고 식별자 획득 방식을 제공하는데, 그것이 SKAN(SKAdNetwork)이다.</p>
<p><img decoding="async" loading="lazy" alt="SKAN winning flow" src="https://bahamoth.github.io/01010011/assets/images/skan_flow-b46d475c0e28be2ceeaa6b0d56e19ec4.png" class="img_IxQR"></p>
<p>SKAN 의 데이터 흐름은 다음과 같다.</p>
<ol>
<li>Ad Network: 광고를 개제</li>
<li>Ad Network: 제한된 Attribution(Postback) 수집 URL 등록</li>
<li>사용자: 광고를 클릭 -&gt; 앱 설치</li>
<li>Apple: 광고사업자가 개인 추적이 어렵도록 일정 기간 지연(~최대 144시간)</li>
<li>Ad Network: 일정시간 경과 후 Postback 으로 캠페인 ID 및 제한된 사용자 정보(Conversion Value) 수신(IDFA 없음)</li>
</ol>
<p>여기서 유일하게 사용자 정보를 얻어낼 수단은 CV(Conversion Value) 뿐이다. CV는 0~63 사이의 정수로 표현되는 6bit 값으로, 광고주는 64 가지 값에 매핑하여 사용자의 앱 설치 후 행동을 수집할 수 있다. 예를 들어 CV가 1이면 튜토리얼 완료, CV가 2이면 최초 인앱 구매 완료 등의 값을 사전에 정의, Postback 시점에 획득하여 사용자를 분석할 수 있다. 알고 있겠지만 6bit 는 메우 제한된 값으로, CV를 단독으로 이용하여 사용자를 특정할 방법은 없다.</p>
<p>말하자면 Apple 은 데이터 측정의 심판이자 유일한 처리자 역할을 자처한다. 광고주, Ad Network 는 모두 Apple 이 정해둔 엄격한 규칙 안에서 Apple이 제공하는 최종 결과물을 수동적으로 받아 해석해야 한다.</p>
<h3 class="anchor anchorWithStickyNavbar_SBA1" id="android-의-privacy-sandbox와-attribution-reporting-api">Android 의 Privacy Sandbox와 Attribution Reporting API<a href="https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era#android-%EC%9D%98-privacy-sandbox%EC%99%80-attribution-reporting-api" class="hash-link" aria-label="Android 의 Privacy Sandbox와 Attribution Reporting API에 대한 직접 링크" title="Android 의 Privacy Sandbox와 Attribution Reporting API에 대한 직접 링크">​</a></h3>
<p>앞서 Apple이 모든 Attribution 획득 경로에 관여, 통제하면서 결과만 전달하는 방식과는 대조적으로, Google은 광고 생태계 참여자들이 개인정보 보호 기술을 기반으로 자체적인 프라이버시 보호 솔루션을 구축할 수 있도록 빌딩블록을 제공한다. 그 핵심 빌딩블록이 바로 Privacy Sandbox 이다.</p>
<p>Privacy Sandbox는 다음 3가지 핵심 목표를 갖는다.</p>
<ol>
<li>기존의 추적 메커니즘을 대체할 새로운 개인정보 보호기술을 구축하는 것.</li>
<li>퍼블리셔와 개발자가 침해적인 추적 없이도 무료 온라인 컨텐츠를 계속 제공할 수 있도록 지원하는 것.</li>
<li>업계와의 협력을 통해 새로운 인터넷 개인정보 보호 표준을 구축하는 것.</li>
</ol>
<p>요약하면, 개인정보를 보호하면서도 퍼블리셔와 개발자가 광고 기반 비즈니스를 지속할 수 있도록 하는 업계 표준을 만드는 것이다.</p>
<p><img decoding="async" loading="lazy" alt="Privacy Sandbox flow" src="https://bahamoth.github.io/01010011/assets/images/sandbox_flow-cab0829337b29544487b725c511d737b.png" class="img_IxQR"></p>
<p>Google의 Privacy Sandbox가 기존의 Attribution 획득방식과 기술적으로 가장 크게 구별되는 부분은 사용자 디바이스 안에서 Ad Network 정보와 매칭되는 Attribution을 만들어낸다는 점이다.</p>
<p>디바이스 안에서 Attribution을 획득하기 때문에 광고 비즈니스 사업자는 사용자의 개인정보를 디바이스 밖으로 빼내지 넘기지 않고도 유의미한 사용자 전환 정보를 얻을 수 있다.</p>
<p>이렇게 사용자 단말에서 생성된 익명화된 Attribution은 Attribution Reporting API(줄여서 ARA)를 통해 수집된다.</p>
<p>ARA를 통해 수집되는 리포트는 크게 2가지 유형이 존재한다.</p>
<ul>
<li><strong>Event-Level Report:</strong> "어떤 광고가 전환을 유도했는가?"와 같이 제한적이지만 세분화된 정보</li>
<li><strong>Summary Reports:</strong> "캠페인의 총매출액과 ROI는 얼마인가?"와 같이 구매 금액 등 상세한 전환 데이터를 암호화 및 집계된 형태로 제공</li>
</ul>
<p>Event Level Report는 익명화된 개별 정보이다. 개별정보이지만 익명화 되어 있기 때문에 많은 정보가 담겨있지는 않다. Attribution 정보와 사용자 클릭, 조회 등의 이벤트를 매핑한 데이터를 제공한다. 이 리포트는 캠페인 도달율 측정이나 Attribution 집계 등의 용도로 적합하다.</p>
<p>반면, Summary Report는 사용자 데이터를 집계한 통계 결과물이다. 개별화된 정보는 없지만 전환가치, ROI, 사용자 세그먼트 별 캠페인 성과분석 등 깊이있는 리포트를 제공한다.</p>
<p>이 데이터들은 암호화된 형태(=encrypted aggregatable report)로 Ad tech platform(Appsflyer, Meta, Applovin 등등..)에게 전달되며, 이 암호화된 데이터를 기반으로 필요한 쿼리를 Cloud Trusted Execution Environment에 위치한 Aggregation Service 에 질의한다.</p>
<blockquote>
<p><strong>Cloud Trusted Execution Environment(TEE)?</strong><br>
<!-- -->TEE란 구글에서 제안하는 보안 기준을 충족하는 &amp; 신뢰할만한 클라우드 제공자의 인프라 위에서 동작하는 격리된 환경이다. TEE의 보안 기준을 충족하면 Ad Tech Platform 기업에서 자체적으로 구축, 운영할 수 있다.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="executive-summary">Executive Summary<a href="https://bahamoth.github.io/01010011/blog/mobile-attribution-in-the-privacy-first-era#executive-summary" class="hash-link" aria-label="Executive Summary�에 대한 직접 링크" title="Executive Summary에 대한 직접 링크">​</a></h2>
<p>지금까지 개인정보 보호의 시대에 어떻게 Mobile Attribution 을 획득할 것인가에 대한 내용을 알아보았다. 과거처럼 Deterministic하게 Attribution을 획득하던 시대는 끝났으며, 각 이해관계자들은 개인정보 보호의 시대의 Attribution 획득 방식을 준비해야 한다.</p>
<p>결정론적 시대의 종말: 개인정보 보호 강화로 IDFA, GAID 기반의 1:1 사용자 추적이 불가능해졌다.</p>
<p>확률론적 시대로의 전환: 이제는 명확한 데이터 대신, 제한된 데이터를 바탕으로 성과를 '추론'해야 한다.</p>
<p>Apple (SKAN)의 접근: Apple이 모든 과정을 통제하는 '블랙박스' 방식이다.</p>
<p>Google (샌드박스)의 접근: <strong>'온디바이스 매칭'</strong> 을 핵심으로, 광고 생태계가 활용할 수 있는 <strong>'빌딩 블록'</strong> 을 제공한다.</p>
<p>Ad Tech의 역할 변화: MMP, 광고 네트워크 등 Ad Tech는 암호화된 리포트를 받아, 직접 클라우드 보안 환경(TEE)에 <strong>'Aggregation Service'</strong> 를 구축하고 운영하여 데이터를 처리해야 한다.</p>]]></content:encoded>
            <category>attribution</category>
            <category>mmp</category>
            <category>ad-network</category>
            <category>skan</category>
            <category>privacy</category>
        </item>
        <item>
            <title><![CDATA[docker-build-hang/docker-build-hang]]></title>
            <link>https://bahamoth.github.io/01010011/blog/2025/03/30/docker-build-hang/docker-build-hang</link>
            <guid>https://bahamoth.github.io/01010011/blog/2025/03/30/docker-build-hang/docker-build-hang</guid>
            <pubDate>Sun, 30 Mar 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[---]]></description>
            <content:encoded><![CDATA[<hr>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="slug-docker-build-hangtitle-build가-가끔씩-멈추는-이유는authors-bahamothtags-alpine-docker-mtu-mss-clamping-pmtud">slug: docker-build-hang
title<!-- -->:Docker<!-- --> build가 가끔씩 멈추는 이유는?
authors: [bahamoth]
tags: [alpine, docker, mtu, mss-clamping, pmtud]<a href="https://bahamoth.github.io/01010011/blog/2025/03/30/docker-build-hang/docker-build-hang#slug-docker-build-hangtitle-build%EA%B0%80-%EA%B0%80%EB%81%94%EC%94%A9-%EB%A9%88%EC%B6%94%EB%8A%94-%EC%9D%B4%EC%9C%A0%EB%8A%94authors-bahamothtags-alpine-docker-mtu-mss-clamping-pmtud" class="hash-link" aria-label="slug-docker-build-hangtitle-build가-가끔씩-멈추는-이유는authors-bahamothtags-alpine-docker-mtu-mss-clamping-pmtud에 대한 직접 링크" title="slug-docker-build-hangtitle-build가-가끔씩-멈추는-이유는authors-bahamothtags-alpine-docker-mtu-mss-clamping-pmtud에 대한 직접 링크">​</a></h2>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="ci가-가끔씩-실패를-한다">CI가 가끔씩 실패를 한다.<a href="https://bahamoth.github.io/01010011/blog/2025/03/30/docker-build-hang/docker-build-hang#ci%EA%B0%80-%EA%B0%80%EB%81%94%EC%94%A9-%EC%8B%A4%ED%8C%A8%EB%A5%BC-%ED%95%9C%EB%8B%A4" class="hash-link" aria-label="CI가 가끔씩 실패를 한다.에 대한 직접 링크" title="CI가 가끔씩 실패를 한다.에 대한 직접 링크">​</a></h2>
<p>CI가 가끔씩 실패를 한다.</p>
<p>이유는 alpine linux docker image를 multi-stage build할 때 간헐적으로 hang이 발생하기 때문이다.<br>
<!-- -->다른 os에서는? ubuntu docker build 에서도 전혀 발생하지 않는다. 오직 hang은 alpine linux를 이용하여 apk add를 수행할 때 간헐적으로 발생한다.<br>
<!-- -->곤란하게도 hang은 매번 발생하지 않는다. 10번 시도하면 4~5번 정도? 대개는 <code>apk add gcc</code> 를 수행할 때 걸리지만, 가끔씩 <code>apk add python</code> 이나 다른 package 빌드할 때도 발생은 한다.<br>
<!-- -->이 현상은 퍼블릭 네트워크를 이용하는 내 개인 PC에서는 발생하지 않으며, 오직 회사의 격리된 private network에서만 발생한다.<br>
<!-- -->이렇게 간헐적으로 발생하는 문제는 추적하기가 힘들다. 원인을 특정하고 정확히 재현해 내기가 어렵기 때문이다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="maximum-transmission-unitmtu">Maximum Transmission Unit(MTU)<a href="https://bahamoth.github.io/01010011/blog/2025/03/30/docker-build-hang/docker-build-hang#maximum-transmission-unitmtu" class="hash-link" aria-label="Maximum Transmission Unit(MTU)에 대한 직접 링크" title="Maximum Transmission Unit(MTU)에 대한 직접 링크">​</a></h2>
<p>그나마 우리에게 주어진 단서는 이 현상이 사내 네트워크와 연관이 있다는거다. 네트워크 관련한 설정을 이것 저것 바꾸거나 tcp packet을 캡처하는 시도를 해볼 수 있다.<br>
<!-- -->네트워크 관련한 여러 가지 시도를 하였고, 그 결과 문제의 원인을 좁힐 다른 단서를 찾을 수 있었다.<br>
<code>docker build --network host</code> 옵션에서는 hang이 전혀 발생하지 않는다. 문제는 docker0 bridge network를 사용할 때만 발생한다.<br>
<!-- -->놀랍게도 docker0 interface의 mtu size 를 500 까지 줄였더니 증상이 사라지는 것을 발견하였다.(종전 mtu=1500, host와 동일)</p>
<p>지금까지의 현상을 정리하면,</p>
<ul>
<li>특정 private network 환경에서</li>
<li>docker bridge network 를 이용하여</li>
<li>alpine linux 의 apk add 명령을 수행할 때</li>
<li>간헐적으로(4~5건 / 10회) network hang 발생</li>
</ul>
<h2></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[should-i-still-write-blogs-in-the-ai-era/should-i-still-write-blogs]]></title>
            <link>https://bahamoth.github.io/01010011/blog/2025/03/20/should-i-still-write-blogs-in-the-ai-era/should-i-still-write-blogs</link>
            <guid>https://bahamoth.github.io/01010011/blog/2025/03/20/should-i-still-write-blogs-in-the-ai-era/should-i-still-write-blogs</guid>
            <pubDate>Thu, 20 Mar 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[---]]></description>
            <content:encoded><![CDATA[<hr>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="slug-should-i-still-write-blogstitle-ai-시대에-여전히-블로그를써야-할까authors-bahamothtags-ai-blog">slug: should-i-still-write-blogs
title: AI 시대에 여전히 블로그를써야 할까?
authors: [bahamoth]
tags: [AI, blog]<a href="https://bahamoth.github.io/01010011/blog/2025/03/20/should-i-still-write-blogs-in-the-ai-era/should-i-still-write-blogs#slug-should-i-still-write-blogstitle-ai-%EC%8B%9C%EB%8C%80%EC%97%90-%EC%97%AC%EC%A0%84%ED%9E%88-%EB%B8%94%EB%A1%9C%EA%B7%B8%EB%A5%BC%EC%8D%A8%EC%95%BC-%ED%95%A0%EA%B9%8Cauthors-bahamothtags-ai-blog" class="hash-link" aria-label="slug: should-i-still-write-blogs
title: AI 시대에 여전히 블로그를써야 할까?
authors: [bahamoth]
tags: [AI, blog]에 대한 직접 링크" title="slug: should-i-still-write-blogs
title: AI 시대에 여전히 블로그를써야 할까?
authors: [bahamoth]
tags: [AI, blog]에 대한 직접 링크">​</a></h2>
<!-- -->
<p>AI의 시대, 위기의 글쓰기 - 기술 블로그를 계속 써야 할까?</p>
<p>블로그에 글을 안 쓴지 3개월 가량 지났다.<br>
<!-- -->다양한 생성형 AI 서비스를 접하면서 블로그에 대한 존재론적 물음이 들었달까?<br>
<!-- -->내가 하루 중에 읽게 되는 컨텐츠, 그 중에서도 기술 컨텐츠의 상당한 비중은 생성형 AI로부터 나온다.
간단한 리눅스 명령어나 쉘스크립트부터 네트워크 패킷 분석이나 관련한 RFC 추적, 핫한 트랜드가 되고 있는 MCP Spec 분석과 구현까지 생성형 AI 가 내놓은</p>
<p>그 사이 AI 기술은 하루가 멀다하고 격변하는 시기를 거치 고 있다. 이제 누구든 코딩 문제가 생기면 구글링보다 빠르게 ChatGPT나 Claude에게 물어보는 시대가 됐다. 이제는 간단한 리눅스 명령어부터 복잡한 SQL 쿼리문, 코드 리뷰와 대체기술까지 알아서 척척 알려주니 굳이 구글링해가며 발품을 팔 이유가 없어졌다.
이쯤 되면 심각한 존재론적 회의가 든다. 이런 초월적 AI 시대에 개발 블로그를 계속 써야 할 이유가 있을까? 수많은 개발 블로그들 사이에서 내 글이 존재 의미가 있을까? 블로그는 차치하고 당장 개발자 커리어를 계속 이어갈 수는 있을까?
당장 어떤 기술 주제로 글쓰기를 시켜도 나보다 클로드가 더 많은 정보를 전달해주는 시대에</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[macOS에서 특정 단축어를 누를 때만 들리는 beep음 없애기]]></title>
            <link>https://bahamoth.github.io/01010011/blog/how-to-mute-the-weired-beep-sound</link>
            <guid>https://bahamoth.github.io/01010011/blog/how-to-mute-the-weired-beep-sound</guid>
            <pubDate>Sun, 15 Dec 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[beep]]></description>
            <content:encoded><![CDATA[<p><img decoding="async" loading="lazy" alt="beep" src="https://bahamoth.github.io/01010011/assets/images/beep-sound-897614d0e38c3eccc58104742e55953a.png" class="img_IxQR"></p>
<p>맥북을!! 샀다!! (!! m4!! pro!! max!! 64GB!! 🎉🎉🎉)</p>
<p>새 맥북에 이전 맥북 설정을 마이그레이션하는 대신 처음부터 맥북을 세팅하기로 결정, 기존에 써보지 못했던 도구들도 하나 둘 알아가는 재미를 즐기고 있다.
터미널 프로그램도 iterm2에서 다른걸 써보려고 Warp를 설치했는데 아주 만족도가 높다.</p>
<p>그런데 황당한 문제가 발생했다. Split pane(Horizontal) 의 크기를 줄이려고 <code>cmd + ctrl + ↓</code> 키를 눌렀더니,</p>
<p>"삑"</p>
<p>beep음이 들리는 것이다.</p>
<p><code>cmd + ctrl + ↓</code> <code>cmd + ctrl + ↓</code></p>
<p>"삑" "삑"</p>
<p>희한하게도 <code>cmd + ctrl + ↑</code> 키를 누를 때는 아무 소리가 나지 않았다.
Warp 뭐야. 시끄럽게. 분할창 크기 조절을 얼마나 자주하는데 이러면 곤란하지. 안타깝지만 곧 나올 Ghostty 나오면 Warp는 폐기다.
라고 생각하고 무심결에 같은 단축키(<code>cmd + ctrl + ↓</code>)를 vs code에서 눌러봤다.</p>
<p>"삑"</p>
<p>어라? vs code에서도 beep음이 나는데? chrome에서도?
평소에 음소거 상태에서 맥북을 이용하기 때문에 &amp; 저 단축키를 누를 일이 없어서 이런 거슬리는 소음 문제가 있다는걸 처음 알게 되었다.
찾아보니 이 문제는 2019년도부터 Warp 터미널 뿐 아니라 다른 앱에서도 여러 차례 보고된 것으로, macOS에서 제대로 키바인딩 처리를 하지 못해 발생하는 것이 원인으로 추정된다. (링크: <a href="https://issues.chromium.org/issues/41432539#comment10" target="_blank" rel="noopener noreferrer">https://issues.chromium.org/issues/41432539#comment10</a>)</p>
<p>해결방법은 다음과 같다.</p>
<p><code>~/Library/KeyBindings/DefaultKeyBinding.dict</code> 파일을 생성하고 아래와 같이 설정, 어플리케이션을 재시작하면 beep음이 꺼진 것을 확인할 수 있다.</p>
<div class="codeBlockContainer_CCLs theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_SaVD"><pre tabindex="0" class="prism-code language-text codeBlock_Z7Ay thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_LibW"><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "@^\UF701" = "noop:";</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "@^\UF702" = "noop:";</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    "@^\UF703" = "noop:";</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup_ILbZ"><button type="button" aria-label="클립보드에 코드 복사" title="복사" class="clean-btn"><span class="copyButtonIcons_Dv9x" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_Hdzs"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_Zyxa"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content:encoded>
            <category>warp</category>
            <category>beep</category>
            <category>macOS</category>
        </item>
        <item>
            <title><![CDATA[호랑이는 죽어서 가죽을 남기고 프로그램은 죽어서 덤프를 남긴다.]]></title>
            <link>https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump</link>
            <guid>https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump</guid>
            <pubDate>Tue, 19 Nov 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[tiger]]></description>
            <content:encoded><![CDATA[<p><img decoding="async" loading="lazy" alt="tiger" src="https://bahamoth.github.io/01010011/assets/images/tiger-5d0083e532ffc889503c91b5a976b4b2.png" class="img_IxQR"></p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="서론">서론<a href="https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump#%EC%84%9C%EB%A1%A0" class="hash-link" aria-label="서론에 대한 직접 링크" title="서론에 대한 직접 링크">​</a></h2>
<p>아무리 소프트웨어를 잘 만들었더라도 구동중인 프로그램이 사용자 환경에서 비정상 종료되는 문제는 필연적이다.</p>
<p>속된 말로 '프로그램이 죽는' 현상이 이러한 비정상 종료에 해당하는데, 개발자 입장에서는 왜 이러한 '죽음'이 발생하는지 파악이 어렵다. 왜냐하면 개발자의 PC에서는 프로그램이 죽지 않기 때문이다.(<a href="https://www.amazon.com/works-Machine-Programming-T-Shirt/dp/B07C9FVM4R" target="_blank" rel="noopener noreferrer">It works on my machine</a>)<br>
<!-- -->너무도 다양한 사용자 환경은 기상천외한 문제를 일으킨다.(<a href="https://beza1e1.tuxen.de/lore/allergic_car.html" target="_blank" rel="noopener noreferrer">바닐라 아이스크림 알러지가 있는 자동차</a>)</p>
<p>이러한 안타까운 죽음의 원인을 부검하기 위해, 개발자는 프로그램이 실행되었던 주변환경에 대한 다양한 정보를 수집한다. 허나 아무리 다양한 주변 정보를 수집한다 하더라도 직접적인 사인은 시체를 확인해야만 하듯, 프로그램이 비정상 종료된 원인은 크래시가 발생한 시점에 메모리에 적재된 스냅샷을 확인해야만 한다.</p>
<p>그렇다. 호랑이는 죽어서 가죽을 남기고 한우는 죽어서 T본 스테이크를 남기듯, 프로그램은 죽어서 메모리 덤프를 남긴다. 이 글에서는 메모리 덤프가 무엇인지 알아보고, 다양한 사용자 환경에서 덤프를 수집하고 처리하기 위해 어떤 과정들이 이뤄지는지를 알아보겠다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="프로그램의-생애주기정상종료-vs-비정상종료">프로그램의 생애주기(정상종료 vs 비정상종료)<a href="https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump#%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8%EC%9D%98-%EC%83%9D%EC%95%A0%EC%A3%BC%EA%B8%B0%EC%A0%95%EC%83%81%EC%A2%85%EB%A3%8C-vs-%EB%B9%84%EC%A0%95%EC%83%81%EC%A2%85%EB%A3%8C" class="hash-link" aria-label="프로그램의 생애주기(정상종료 vs 비정상종료)에 대한 직접 링크" title="프로그램의 생애주기(정상종료 vs 비정상종료)에 대한 직접 링크">​</a></h2>
<p>프로그램의 비정상 종료가 무엇인지 설명하려면 정상적으로 실행되어 종료되는 상황이 어떤 흐름으로 진행되는지 알아둘 필요가 있다.</p>
<p>먼저 소스코드가 실행가능한 프로그램으로 변환되는 과정을 개략적으로 살펴보자. 컴파일러는 소스코드를 역할에 따라 다양한 중간형태(=Object File)로 변환한다.<br>
<!-- -->다음은 Linux의 Object File 형식이다. 다른 플랫폼의 경우 명칭이 좀 다를 수 있으나 개념은 크게 다르지 않다.</p>
<p><img decoding="async" loading="lazy" alt="elf overview" src="https://bahamoth.github.io/01010011/assets/images/elf-overview-d6d0d5dd85ffedfb37e5c2357752313d.png" title="ELF Overview" class="img_IxQR">
<em>출처: <a href="https://cs4157.github.io/www/2024-1/lect/15-elf-intro.html" target="_blank" rel="noopener noreferrer">https://cs4157.github.io/www/2024-1/lect/15-elf-intro.html</a></em></p>
<ul>
<li><strong>text section:</strong> 컴파일 타겟 머신에서 실행 가능한 기계어 코드</li>
<li><strong>data section:</strong> 초기화된 전역변수/static 변수</li>
<li><strong>bss section:</strong> 초기화되지 않은 전역변수의 메타정보</li>
<li><strong>그밖에:</strong> 읽기 전용(rodata)나 심볼테이블(symtab) relocation 정보(rel.text/rel.data) 등등</li>
</ul>
<p>이 중간형태의 Object file들이 실행가능한 형태의 Executable file로 결합이 되어야 비로소 최종적인 프로그램의 형태가 된다.</p>
<blockquote>
<p>Java나 Python, Typescript 같은 Managed 환경은 동작방식도 다르고, 이 글의 메인 주제인 Crash Dump를 (웬만하면)남기지 않기 때문에 여기서는 다루지 않는다.</p>
</blockquote>
<p>프로그램이 실행되기 위해서는 Object file들을 결합 후 메모리에 적재하여야 한다. 이 과정에서 링커는 여러 오브젝트 파일을 하나의 실행 파일로 결합하고, 로더는 이 실행 파일을 메모리에 적재한다. 이 실행파일 형식은 플랫폼에 따라 다르다.</p>
<ul>
<li><strong>Windows:</strong> PE(Portable Executable)</li>
<li><strong>Linux:</strong> ELF(Executable and Linkable Format)</li>
<li><strong>macOS:</strong> Mach-O(Mach Object)</li>
</ul>
<p>프로그램이 메모리에 적재되었을 때 text / data / bss 같은 영역의 크기는 고정적이다. 한편, 프로그램이 동작함에 따라 동적으로 크기가 늘었다 줄었다 하는 영역이 있는데, TLS(Thread Local Storage)에서 자라나는 콜스택이나 힙이 그러한 예이다. 콜스택은 함수 호출 시 스택 프레임을 추가하고, 함수 종료 시 제거하는 구조다. 힙은 프로그램 실행 중 메모리를 할당하고 해제하는 영역이다.</p>
<p>프로그램의 특정 기능을 사용하기 위해 버튼을 누르거나, 화면을 터치하는 등의 행위를 하면 그 기능을 수행하기 위해 구성된 함수들이 차례대로 호출된다. 때로는 크기가 얼마나 될지 모르는 데이터를 읽고 쓰는 작업이 필요하기도 하다. 이 과정에서 콜스택과 힙이 자라나게 된다.</p>
<p>정상적인 사용자 시나리오에서는 프로그램이 모든 작업을 마치고 종료될 때, 콜스택과 힙에 할당된 모든 메모리가 정리되고, 모든 리소스는 OS에 반환된다. 이로써 프로그램은 정상 종료 상태에 진입하게 된다.</p>
<blockquote>
<p><code>Alt + X</code> 나 <code>Ctrl + C</code> 로 프로세스를 중단시키는 것도 정상 종료의 범주에 들어야 할까? 관점에 따라 다르겠지만 일단 필자가 글을 통해 다루려는건 회복 불가능한 상태에 진입한 프로그램이다. <code>Alt + X</code> 나 <code>Ctrl + C</code>로 프로그램을 종료한다는건 사용자의 의도에 의해 프로그램이 종료되는 것이므로 이 글에서는 정상 종료로 간주한다.</p>
</blockquote>
<p>하지만 프로그램이 예기치 못한 상황에 직면하면 비정상 종료가 발생할 수 있다. 이는 마치 사람이 가서는 안 되는 곳 - 군사분계선 바깥 지역이나 은행 금고 등 -에 발을 들이거나, 다른 사람들에게 치명적인 피해를 입히는 행위를 했을 때 정부가 이를 제재하고 감옥으로 보내는 것과 비슷하다. 마찬가지로 OS도 시스템의 안정성을 위해 계약되지 않은 행위를 하는 프로그램을 강제로 종료시킨다. 시스템 메모리의 보호된 영역 또는 잘못된 주소를 참조하거나, 리소스를 과도하게 점유하는 경우 운영체제는 해당 프로그램을 강제로 종료하는데, 이것이 우리가 흔히 말하는 크래시이다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="예외처리">예외처리<a href="https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump#%EC%98%88%EC%99%B8%EC%B2%98%EB%A6%AC" class="hash-link" aria-label="예외처리에 대한 직접 링크" title="예외처리에 대한 직접 링크">​</a></h2>
<p>이러한 갑작스러운 비정상 종료를 제어하기 위해 프로그래밍 언어와 운영체제는 예외처리 수단을 제공한다. 이 글에서는 OS 수준의 예외처리에 대해서만 다룬다.</p>
<ul>
<li><strong>Windows:</strong> SEH(Structured Exception Handling)</li>
<li><strong>Linux:</strong> Signal</li>
<li><strong>macOS:</strong> Mach Exception &amp; Signal(Mach Exception의 우선순위가 더 높음)</li>
</ul>
<p><strong>비교 표: 플랫폼별 관리 예외/신호</strong></p>
<div class="table__4f0"><table><thead><tr><th><strong>문제 유형</strong></th><th><strong>Windows (SEH)</strong></th><th><strong>Linux (Signals)</strong></th><th><strong>macOS (Mach + Signals)</strong></th></tr></thead><tbody><tr><td><strong>잘못된 메모리 접근</strong></td><td>STATUS_ACCESS_VIOLATION</td><td>SIGSEGV, SIGBUS</td><td>SIGSEGV, SIGBUS, EXC_BAD_ACCESS</td></tr><tr><td><strong>스택 오버플로우</strong></td><td>STATUS_STACK_OVERFLOW</td><td>SIGSEGV (간접적으로 발생)</td><td>SIGSEGV (간접적으로 발생)</td></tr><tr><td><strong>잘못된 명령어</strong></td><td>STATUS_ILLEGAL_INSTRUCTION</td><td>SIGILL</td><td>SIGILL, EXC_BAD_INSTRUCTION</td></tr><tr><td><strong>0으로 나누기 등</strong></td><td>STATUS_FLOAT_DIVIDE_BY_ZERO</td><td>SIGFPE</td><td>SIGFPE, EXC_ARITHMETIC</td></tr><tr><td><strong>리소스 초과</strong></td><td>STATUS_INSUFFICIENT_RESOURCES</td><td>SIGXCPU, SIGXFSZ</td><td>SIGXCPU, SIGXFSZ</td></tr></tbody></table></div>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="os-별로-서로-다른-덤프-포맷">OS 별로 서로 다른 덤프 포맷<a href="https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump#os-%EB%B3%84%EB%A1%9C-%EC%84%9C%EB%A1%9C-%EB%8B%A4%EB%A5%B8-%EB%8D%A4%ED%94%84-%ED%8F%AC%EB%A7%B7" class="hash-link" aria-label="OS 별로 서로 다른 덤프 포맷에 대한 직접 링크" title="OS 별로 서로 다른 덤프 포맷에 대한 직접 링크">​</a></h2>
<p>크래시가 발생하면 운영체제는 메모리 스냅샷을 기록하여 디버깅과 원인 분석에 활용한다. 그러나 각 운영체제는 크래시 시점의 메모리 상태를 저장하는 방식과 포맷이 서로 다르다. 각 OS는 고유의 덤프 포맷을 사용하여 크래시 상황을 분석하는 데 필요한 정보를 제공한다.</p>
<p><strong>1. Windows</strong></p>
<ul>
<li><strong>Minidump</strong>: Windows 운영체제는 Minidump 포맷을 사용하여 크래시 정보를 저장한다. Minidump는 크래시 원인을 분석하는 데 필요한 최소한의 정보를 포함하며, 파일 크기가 작아 전송과 분석이 용이하다. 보통은 힙을 포함하지 않으며, 옵션으로 힙 영역을 포함시키더라도 전체 내용을 포함하지 않기 때문에 파일 크기가 상대적으로 작다.</li>
<li><strong>Full Dump</strong>: 전체 메모리 덤프를 포함하여 크래시 시점의 모든 메모리 상태를 기록한다. 힙, 전역변수, 확장 레지스터, 기타 리소스 등의 모든 내용을 포함하여 파일 크기가 크고 분석이 복잡할 수 있다.</li>
</ul>
<p><strong>2. Linux</strong></p>
<ul>
<li><strong>Core Dump</strong>: Linux 운영체제는 Core Dump 포맷을 사용하여 크래시 정보를 저장한다. Core Dump는 프로세스의 메모리 이미지와 레지스터 상태를 포함하며, 디버깅에 유용한 정보를 제공한다. 그러나 파일 크기가 크고 다루기 어려운 경우가 많다.</li>
</ul>
<p><strong>3. macOS</strong></p>
<ul>
<li><strong>Apple Crash Report</strong>: macOS는 Apple Crash Report 포맷을 사용하여 크래시 정보를 저장한다. 이 포맷은 크래시 시점의 스택 트레이스, 메모리 내용, 레지스터 상태 등을 포함하며, 분석을 위해 Xcode와 같은 도구와 함께 사용된다.</li>
</ul>
<p><strong>4. Android</strong></p>
<ul>
<li><strong>Tombstone</strong>: Android 운영체제는 Tombstone 포맷을 사용하여 크래시 정보를 저장한다. Tombstone은 크래시 시점의 스택 트레이스, 메모리 내용, 레지스터 상태 등을 포함하며, adb와 같은 도구를 사용하여 분석할 수 있다.</li>
</ul>
<p>이렇듯 각 운영체제의 덤프 포맷은 크래시 원인 분석에 필요한 정보를 제공하지만, 그 구조가 다르기 때문에 크로스 플랫폼 환경에서 어플리케이션을 배포하는 개발자는 파편화된 덤프 포맷을 일일이 관리해야 한다. 이는 고통스러운 작업이기에 덤프를 다루는 일관된 방법이 필요해지는 이유가 된다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="minidump-format-과-chromium-breakpad-project">Minidump Format 과 Chromium Breakpad Project<a href="https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump#minidump-format-%EA%B3%BC-chromium-breakpad-project" class="hash-link" aria-label="Minidump Format 과 Chromium Breakpad Project에 대한 직접 링크" title="Minidump Format 과 Chromium Breakpad Project에 대한 직접 링크">​</a></h2>
<p>지금까지 우리가 알아본 것을 요약하면,</p>
<ul>
<li>프로그램은 정상적으로 실행되다가 예기치 못한 상황에 직면하면 비정상 종료한다.</li>
<li>운영체제는 비정상 종료 시점의 메모리 스냅샷을 저장하여 디버깅과 원인 분석에 활용한다.</li>
<li>각 운영체제는 프로그램의 메모리 적재 방식이 서로 다르며, <strong>크래시 덤프 포맷도 다르다.</strong></li>
<li>또한 각 운영체제마다 <strong>예외를 처리하는 방식도 다르다.</strong></li>
</ul>
<p>브라우저나 JVM, .NET 처럼 크로스 플랫폼 환경에서도 동일한 방식의 동작을 보장하는 레이어를 지닌 어플리케이션은 위와 같은 크래시 덤프의 수집 및 분석 시 파편화 문제가 크게 체감되지 않을 수 있다. 허나 여러 플랫폼 타겟을 지원하는 네이티브 어플리케이션의 경우, 이러한 크래시 파편화는 개발자가 문제를 찾기 어렵게 한다.</p>
<p>2008년 9월, 구글은 <a href="https://blog.chromium.org/2008/09/welcome-to-chromium_02.html" target="_blank" rel="noopener noreferrer">Chromium이라는 오픈소스 웹브라우저 프로젝트를 발표</a>하였는데, 이 프로젝트의 주요 목표 중 하나는 모든 플랫폼에서 일관된 사용자 경험을 제공하는데 있었다. 필연적으로 여러 플랫폼에서 발생하는 크래시 정보를 효과적으로 수집하고 분석하기 위한 수단이 필요했는데, 이를 위한 Chromium의 해결책이 바로 <a href="https://chromium.googlesource.com/breakpad/breakpad/" target="_blank" rel="noopener noreferrer"><strong>Breakpad Project</strong></a>이다.</p>
<p>Microsoft의 Minidump 포맷은 Breakpad에서 크로스플랫폼 환경에서 일관된 크래시 덤프 수집을 위해 채택한 형식이다. <a href="https://chromium.googlesource.com/breakpad/breakpad/+/HEAD/docs/processor_design.md" target="_blank" rel="noopener noreferrer">Breakpad Processor 디자인 문서</a>에 따르면 왜 Minidump 포맷을 선택하였는지에 대한 이유가 자세히 기술되어 있다.</p>
<ul>
<li><strong>경량화된 포맷:</strong> Minidump는 크래시 원인을 분석하는 데 필요한 최소한의 정보만을 포함하며, 파일 크기가 작아 전송과 분석이 용이하다.</li>
<li><strong>확장성:</strong> 다양한 CPU 아키텍처 및 운영체제를 지원하도록 설계되었으며, 다른 포맷들과는 다르게 확장이 용이하다.</li>
<li><strong>검증된 도구:</strong> Minidump 포맷은 Windows 운영체제에서 수 년간 검증된 포맷이기 때문에 안정성이 높으며, MS의 디버깅 도구들을 활용할 수 있다.</li>
</ul>
<blockquote>
<p>눈치빠른 사람들은 여기서 아직 해결되지 못한 파편화 문제를 알아챌 것이다. 바로 Debugging Symbol인데, Minidump를 쓰더라도 플랫폼 별로 서로 다른 Symbol 포맷은 여전히 문제가 된다.<br>
<!-- -->이에 대한 Breakpad의 해법은 각 플랫폼의 Symbol을 Breakpad 만의 Human-Readable한 <a href="https://chromium.googlesource.com/breakpad/breakpad/+/HEAD/docs/symbol_files.md" target="_blank" rel="noopener noreferrer">고유의 Symbol Format</a>으로 변환하는 것이다.</p>
</blockquote>
<br>
<p>아래 그림은 Breakpad 프로젝트가 어떻게 동작하는지에 대한 개략적인 flow를 보여준다.
<img decoding="async" loading="lazy" alt="breakpad flow" src="https://bahamoth.github.io/01010011/assets/images/breakpad-flow-3f2df50e8eabf9ea66f3882c014e5482.png" class="img_IxQR"></p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="breakpad의-한계와-이를-개선하는-프로젝트들crashpad-rust-minidump">Breakpad의 한계와 이를 개선하는 프로젝트들(Crashpad, Rust-Minidump)<a href="https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump#breakpad%EC%9D%98-%ED%95%9C%EA%B3%84%EC%99%80-%EC%9D%B4%EB%A5%BC-%EA%B0%9C%EC%84%A0%ED%95%98%EB%8A%94-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%EB%93%A4crashpad-rust-minidump" class="hash-link" aria-label="Breakpad의 한계와 이를 개선하는 프로젝트들(Crashpad, Rust-Minidump)에 대한 직접 링크" title="Breakpad의 한계와 이를 개선하는 프로젝트들(Crashpad, Rust-Minidump)에 대한 직접 링크">​</a></h2>
<p><img decoding="async" loading="lazy" alt="breakpad with caliper" src="https://bahamoth.github.io/01010011/assets/images/breakpad-with-caliper-17c4ce1433c2707451eaad73a8741f17.png" class="img_IxQR">
Breakpad Client를 사용해보면 가끔씩 제대로 된 덤프가 수집되지 않는 경우가 있다. Breakpad Client가 덤프를 생성할 충분한 시간을 확보하지 못하거나, 덤프 생성 중에 프로세스가 비정상 종료되는 경우가 그 예이다. 앞서 그림을 보면 Breakpad Client는 사용자의 어플리케이션 프로세스 내부에서 동작하도록 설계되어 있는데, 어플리케이션이 종료되는 상황에서는 Breakpad Client가 덤프를 생성할 충분한 시간을 확보하지 못할 수도 있다.<br>
<a href="https://chromium.googlesource.com/crashpad/crashpad" target="_blank" rel="noopener noreferrer">Crashpad</a>는 이러한 한계를 극복하기 위한 개선 프로젝트로, 별도의 Crash 수집 및 전송을 담당하는 Handler Process를 구성하여 이 문제를 해결하였다.
<img decoding="async" loading="lazy" alt="crashpad overview" src="https://bahamoth.github.io/01010011/assets/images/crashpad-overview-67ff10cd6f61eddca7160f3110892e13.png" class="img_IxQR"></p>
<p>한편, Chromium의 Breakpad가 쌓아놓은 유산을 토대로 RIIR(Re-write It in Rust)한 <a href="https://github.com/rust-minidump/rust-minidump" target="_blank" rel="noopener noreferrer">Rust-Minidump</a> 프로젝트도 주목할 만 하다. 2017년 luser라는 개발자가 Rust User Forum에 처음으로 소개한 이 프로젝트는 Rust 언어로 작성하였다는 것 만으로도 다양한 장점(메모리 안정성, 속도, 사용 편의성)을 갖고 있을 뿐 아니라 Rust Crate의 확장성을 활용하여 사용자가 원하는 기능을 쉽게 추가할 수도 있다. 덤프 분석 결과물을 JSON 형태로 출력해주는 편의 기능이나 cli 도구도 제공하므로 덤프 분석을 원하는 개발자들은 다양한 용도로 활용이 가능할 것이다.</p>
<h2 class="anchor anchorWithStickyNavbar_SBA1" id="결론">결론<a href="https://bahamoth.github.io/01010011/blog/how-to-collect-crash-dump#%EA%B2%B0%EB%A1%A0" class="hash-link" aria-label="결론에 대한 직접 링크" title="결론에 대한 직접 링크">​</a></h2>
<p>지금까지 크로스플랫폼 환경에서 발생하는 다양한 덤프를 수집하기 위해 알아야 하는 배경지식과, 파편화 문제를 해결해주는 Breakpad 프로젝트를 위시한 Crashpad, Rust-Minidump 등에 대해 알아보았다. 대개는 Sentry나 Google Crashlytics 등의 Managed Service를 사용하느라 직접 어플리케이션 덤프를 수집하고 분석할 일이 많지 않겠지만 어느 정도 규모가 있는 서비스를 운영, 직접 덤프를 수집하여야만 하는 개발자에게 이 글이 도움이 되길 바란다.</p>
<blockquote>
<p>교양으로 알아둬도 괜찮지 않을까?</p>
</blockquote>]]></content:encoded>
            <category>crash</category>
            <category>minidump</category>
            <category>breakpad</category>
            <category>crashpad</category>
            <category>rust-minidump</category>
        </item>
    </channel>
</rss>